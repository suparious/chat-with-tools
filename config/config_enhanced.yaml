# Chat with Tools Configuration
# ==============================
# This configuration file supports environment variables for sensitive data.
# Set environment variables to override config values:
# - OPENROUTER_API_KEY: Your OpenRouter API key
# - OPENROUTER_BASE_URL: API endpoint URL
# - OPENROUTER_MODEL: Model to use

# OpenRouter API Settings
# -----------------------
openrouter:
  # API key for OpenRouter (required)
  # Set via environment variable OPENROUTER_API_KEY for security
  api_key: ""
  
  # API endpoint URL
  # For OpenRouter: https://openrouter.ai/api/v1
  # For local vLLM: http://localhost:8081/v1
  base_url: "http://localhost:8081/v1"
  
  # Model selection
  # IMPORTANT: Choose a model with high context window (200k+ tokens recommended)
  # for multi-agent orchestration to handle large combined responses
  # 
  # Popular options:
  # - anthropic/claude-3-opus-20240229 (200k context)
  # - anthropic/claude-3-sonnet-20240229 (200k context)
  # - openai/gpt-4-1106-preview (128k context)
  # - google/gemini-pro-1.5 (1M context)
  model: "Orion-zhen/DeepHermes-3-Llama-3-8B-Preview-AWQ"

# System Prompt
# -------------
system_prompt: |
  You are a helpful research assistant with access to various tools.
  
  When users ask questions that require current information, web search,
  calculations, or file operations, use the appropriate tools to gather
  information and provide comprehensive, accurate answers.
  
  IMPORTANT: When you have fully satisfied the user's request and provided
  a complete answer, you MUST call the mark_task_complete tool with a
  summary of what was accomplished. This signals that the task is finished.
  
  Be thorough, accurate, and cite your sources when using search results.

# Agent Settings
# --------------
agent:
  # Maximum iterations before forcing completion
  max_iterations: 10
  
  # Temperature for response generation (0.0-1.0)
  # Lower = more focused, Higher = more creative
  temperature: 0.7
  
  # Maximum tokens per response (null for model default)
  max_tokens: null
  
  # Rate limit (requests per second)
  rate_limit: 10

# Orchestrator Settings
# --------------------
orchestrator:
  # Number of agents to run in parallel
  # More agents = more comprehensive but slower/costlier
  parallel_agents: 4
  
  # Timeout per agent in seconds
  task_timeout: 300
  
  # Result aggregation strategy
  # Options: "consensus" (AI synthesis), "merge" (simple combination)
  aggregation_strategy: "consensus"
  
  # Dynamic question generation prompt
  # Used to decompose user queries into specialized sub-questions
  question_generation_prompt: |
    You are an orchestrator that needs to create {num_agents} different
    questions to thoroughly analyze this topic from multiple angles.
    
    Original user query: {user_input}
    
    Generate exactly {num_agents} different, specific questions that will
    help gather comprehensive information about this topic. Each question
    should approach the topic from a different angle:
    - Research and facts
    - Analysis and insights
    - Verification and validation
    - Alternative perspectives
    
    Return your response as a JSON array of strings:
    ["question 1", "question 2", "question 3", "question 4"]
    
    Only return the JSON array, nothing else.

  # Synthesis prompt for combining agent responses
  synthesis_prompt: |
    You have {num_responses} different AI agents that analyzed the same
    query from different perspectives. Your job is to synthesize their
    responses into ONE comprehensive final answer.
    
    Here are all the agent responses:
    
    {agent_responses}
    
    IMPORTANT: Synthesize these into ONE final comprehensive answer that:
    - Combines the best information from all agents
    - Resolves any contradictions with the most reliable information
    - Provides a complete, coherent response
    - Maintains accuracy and cites sources where appropriate
    
    Do NOT call any tools or mention that you are synthesizing.
    Simply provide the final synthesized answer directly.

# Search Tool Settings
# -------------------
search:
  # Maximum search results to return
  max_results: 5
  
  # User agent string for web requests
  user_agent: "Mozilla/5.0 (compatible; Chat-with-Tools/1.0)"
  
  # Cache TTL in seconds (3600 = 1 hour)
  cache_ttl: 3600
  
  # Maximum content length to fetch (characters)
  max_content_length: 5000
  
  # Request timeout in seconds
  request_timeout: 10
  
  # Blocked domains for security (partial matches)
  blocked_domains:
    - localhost
    - 127.0.0.1
    - 0.0.0.0
    - 192.168.
    - 10.
    - 172.16.
    - internal
    - .local

# Logging Settings
# ----------------
logging:
  # Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
  level: INFO
  
  # Log file path (null to disable file logging)
  file: null
  
  # Log format
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Performance Settings
# -------------------
performance:
  # Enable connection pooling for API clients
  connection_pooling: true
  
  # Enable response caching
  enable_cache: true
  
  # Enable metrics collection
  collect_metrics: true
  
  # Maximum concurrent tool executions
  max_concurrent_tools: 3

# Security Settings
# -----------------
security:
  # Validate all URLs before fetching
  validate_urls: true
  
  # Maximum file size for file operations (bytes)
  max_file_size: 10485760  # 10MB
  
  # Allowed file extensions for read/write operations
  allowed_extensions:
    - .txt
    - .md
    - .json
    - .yaml
    - .yml
    - .csv
    - .log
    - .py
    - .js
    - .html
    - .css

# Development Settings
# -------------------
development:
  # Enable debug mode (verbose logging)
  debug: false
  
  # Enable tool execution tracing
  trace_tools: false
  
  # Save conversation history
  save_history: false
  
  # History directory
  history_dir: "./chat_history"
