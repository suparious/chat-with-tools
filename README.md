# ğŸš€ Chat with Tools

A Python framework to emulate **Grok heavy** functionality using a powerful multi-agent system. Built on OpenRouter's API, Chat with Tools delivers comprehensive, multi-perspective analysis through intelligent agent orchestration.

## ğŸŒŸ Features

- **ğŸ§  Grok heavy Emulation**: Multi-agent system that delivers deep, comprehensive analysis like Grok heavy mode
- **ğŸ”€ Parallel Intelligence**: Deploy 4 specialized agents simultaneously for maximum insight coverage
- **ğŸ¯ Dynamic Question Generation**: AI creates custom research questions tailored to each query
- **âš¡ Real-time Orchestration**: Live visual feedback during multi-agent execution
- **ğŸ› ï¸ Hot-Swappable Tools**: Automatically discovers and loads tools from the `tools/` directory
- **ğŸ”„ Intelligent Synthesis**: Combines multiple agent perspectives into unified, comprehensive answers
- **ğŸ® Single Agent Mode**: Run individual agents for simpler tasks with full tool access

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- [uv](https://github.com/astral-sh/uv) (recommended Python package manager)
- OpenRouter API key

### Installation

1. **Clone and setup environment:**
```bash
git clone <https://github.com/Suparious/chat-with-tools.git>
cd "Chat with Tools"

# Create virtual environment with uv
uv venv

# Activate virtual environment
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

2. **Install dependencies:**
```bash
uv pip install -r requirements.txt
```

3. **Configure API key:**
```bash
# Edit config/config.yaml and replace YOUR API KEY HERE with your OpenRouter API key
```

## ğŸ¯ Usage

### Single Agent Mode

Run a single intelligent agent with full tool access:

```bash
python demos/main.py
```

**What it does:**
- Loads a single agent with all available tools
- Processes your query step-by-step
- Uses tools like web search, calculator, file operations
- Returns comprehensive response when task is complete

**Example:**
```
User: Research the latest developments in AI and summarize them
Agent: [Uses search tool, analyzes results, provides summary]
```

### Grok heavy Mode (Multi-Agent Orchestration)

Emulate Grok heavy's deep analysis with 4 parallel intelligent agents:

```bash
python demos/council_chat.py
```

**How Chat with Tools works:**
1. **ğŸ¯ AI Question Generation**: Creates 4 specialized research questions from your query
2. **ğŸ”€ Parallel Intelligence**: Runs 4 agents simultaneously with different analytical perspectives
3. **âš¡ Live Progress**: Shows real-time agent status with visual progress bars
4. **ğŸ”„ Intelligent Synthesis**: Combines all perspectives into one comprehensive Grok heavy-style answer

**Example Flow:**
```
User Query: "Who is Pietro Schirano?"

AI Generated Questions:
- Agent 1: "Research Pietro Schirano's professional background and career history"
- Agent 2: "Analyze Pietro Schirano's achievements and contributions to technology"  
- Agent 3: "Find alternative perspectives on Pietro Schirano's work and impact"
- Agent 4: "Verify and cross-check information about Pietro Schirano's current role"

Result: Grok heavy-style comprehensive analysis combining all agent perspectives
```

## ğŸ—ï¸ Architecture

### Orchestration Flow

```mermaid
graph TD
    A[User Input] --> B[Question Generation Agent]
    B --> C[Generate 4 Specialized Questions]
    C --> D[Parallel Agent Execution]
    D --> E[Agent 1: Research]
    D --> F[Agent 2: Analysis] 
    D --> G[Agent 3: Alternatives]
    D --> H[Agent 4: Verification]
    E --> I[Synthesis Agent]
    F --> I
    G --> I
    H --> I
    I --> J[Comprehensive Final Answer]
```

### Core Components

#### 1. Agent System (`agent.py`)
- **Self-contained**: Complete agent implementation with tool access
- **Agentic Loop**: Continues working until task completion
- **Tool Integration**: Automatic tool discovery and execution
- **Configurable**: Uses `config.yaml` for all settings

#### 2. Orchestrator (`orchestrator.py`)
- **Dynamic Question Generation**: AI creates specialized questions
- **Parallel Execution**: Runs multiple agents simultaneously  
- **Response Synthesis**: AI combines all agent outputs
- **Error Handling**: Graceful fallbacks and error recovery

#### 3. Tool System (`tools/`)
- **Auto-Discovery**: Automatically loads all tools from directory
- **Hot-Swappable**: Add new tools by dropping files in `tools/`
- **Standardized Interface**: All tools inherit from `BaseTool`

### Available Tools

| Tool | Purpose | Parameters |
|------|---------|------------|
| `search_web` | Web search with DuckDuckGo | `query`, `max_results` |
| `calculate` | Safe mathematical calculations | `expression` |
| `read_file` | Read file contents | `path`, `head`, `tail` |
| `write_file` | Create/overwrite files | `path`, `content` |
| `mark_task_complete` | Signal task completion | `task_summary`, `completion_message` |
| **`sequential_thinking`** | Step-by-step reasoning with revisions | `action`, `thought`, `confidence` |
| **`memory`** | Persistent memory storage | `action`, `content`, `tags` |
| **`python_executor`** | Safe Python code execution | `code`, `description` |
| **`summarizer`** | Text summarization and analysis | `action`, `text`, `ratio` |

## âš™ï¸ Configuration

Edit `config/config.yaml` to customize behavior:

```yaml
# OpenRouter API settings
openrouter:
  api_key: "YOUR KEY"
  base_url: "https://openrouter.ai/api/v1"
  model: "openai/gpt-4.1-mini"  # Change model here

# Agent settings
agent:
  max_iterations: 10

# Orchestrator settings
orchestrator:
  parallel_agents: 4  # Number of parallel agents
  task_timeout: 300   # Timeout per agent (seconds)
  
  # Dynamic question generation prompt
  question_generation_prompt: |
    You are an orchestrator that needs to create {num_agents} different questions...
    
  # Response synthesis prompt  
  synthesis_prompt: |
    You have {num_responses} different AI agents that analyzed the same query...

# Tool settings
search:
  max_results: 5
  user_agent: "Mozilla/5.0 (compatible; OpenRouter Agent)"
```

## ğŸ”§ Development

### Adding New Tools

1. Create a new file in `tools/` directory
2. Inherit from `BaseTool`
3. Implement required methods:

```python
from .base_tool import BaseTool

class MyCustomTool(BaseTool):
    @property
    def name(self) -> str:
        return "my_tool"
    
    @property
    def description(self) -> str:
        return "Description of what this tool does"
    
    @property
    def parameters(self) -> dict:
        return {
            "type": "object",
            "properties": {
                "param": {"type": "string", "description": "Parameter description"}
            },
            "required": ["param"]
        }
    
    def execute(self, param: str) -> dict:
        # Tool implementation
        return {"result": "success"}
```

4. The tool will be automatically discovered and loaded!

### Customizing Models

Supports any OpenRouter-compatible model:

```yaml
openrouter:
  model: "anthropic/claude-3.5-sonnet"     # For complex reasoning
  model: "openai/gpt-4.1-mini"             # For cost efficiency  
  model: "google/gemini-2.0-flash-001"     # For speed
  model: "meta-llama/llama-3.1-70b"        # For open source
```

### Adjusting Agent Count

Change number of parallel agents:

```yaml
orchestrator:
  parallel_agents: 6  # Run 6 agents instead of 4
```

**Note**: Make sure your OpenRouter plan supports the concurrent usage!

## ğŸ® Examples

### Research Query
```bash
User: "Analyze the impact of AI on software development in 2024"

Single Agent: Comprehensive research report
Grok heavy Mode: 4 specialized perspectives combined into deep, multi-faceted analysis
```

### Technical Question  
```bash
User: "How do I optimize a React application for performance?"

Single Agent: Step-by-step optimization guide
Grok heavy Mode: Research + Analysis + Alternatives + Verification = Complete expert guide
```

### Creative Task
```bash
User: "Create a business plan for an AI startup"

Single Agent: Structured business plan
Grok heavy Mode: Market research + Financial analysis + Competitive landscape + Risk assessment
```

## ğŸ› ï¸ Troubleshooting

### Common Issues

**API Key Error:**
```
Error: Invalid API key
Solution: Update config.yaml with valid OpenRouter API key
```

**Tool Import Error:**
```
Error: Could not load tool from filename.py
Solution: Check tool inherits from BaseTool and implements required methods
```

**Synthesis Failure:**
```
ğŸš¨ SYNTHESIS FAILED: [error message]
Solution: Check model compatibility and API limits
```

**Timeout Issues:**
```
Agent timeout errors
Solution: Increase task_timeout in config.yaml
```

### Debug Mode

For detailed debugging, modify orchestrator to show synthesis process:

```python
# In orchestrator.py
synthesis_agent = OpenRouterAgent(silent=False)  # Enable debug output
```

## ğŸ“ Project Structure

```
chat-with-tools/
â”œâ”€â”€ main.py                 # Main launcher script
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ LICENSE                 # License file
â”œâ”€â”€ .gitignore              # Git ignore file
â”œâ”€â”€ src/                    # Core framework code
â”‚   â”œâ”€â”€ __init__.py         # Package initialization
â”‚   â”œâ”€â”€ agent.py            # Core agent implementation
â”‚   â”œâ”€â”€ agent_enhanced.py   # Enhanced agent with error handling
â”‚   â”œâ”€â”€ orchestrator.py     # Multi-agent orchestration logic
â”‚   â”œâ”€â”€ utils.py            # Utility functions
â”‚   â””â”€â”€ tools/              # Tool system
â”‚       â”œâ”€â”€ __init__.py     # Auto-discovery system
â”‚       â”œâ”€â”€ base_tool.py    # Tool base class
â”‚       â”œâ”€â”€ search_tool.py  # Web search tool
â”‚       â”œâ”€â”€ calculator_tool.py      # Math calculations
â”‚       â”œâ”€â”€ memory_tool.py          # Memory storage
â”‚       â”œâ”€â”€ python_executor_tool.py # Python code execution
â”‚       â”œâ”€â”€ sequential_thinking_tool.py # Step-by-step reasoning
â”‚       â”œâ”€â”€ summarization_tool.py   # Text summarization
â”‚       â”œâ”€â”€ read_file_tool.py       # File reading
â”‚       â”œâ”€â”€ write_file_tool.py      # File writing
â”‚       â””â”€â”€ task_done_tool.py       # Task completion
â”œâ”€â”€ demos/                  # Demo applications
â”‚   â”œâ”€â”€ main.py             # Simple chat demo
â”‚   â”œâ”€â”€ council_chat.py     # Multi-agent orchestrator demo
â”‚   â”œâ”€â”€ demo_api.py         # API-based tool demonstrations
â”‚   â”œâ”€â”€ demo_enhanced.py    # Enhanced agent demo
â”‚   â”œâ”€â”€ demo_new_tools.py   # New tools showcase
â”‚   â””â”€â”€ demo_standalone.py  # Standalone tool demos
â”œâ”€â”€ tests/                  # Test files
â”‚   â”œâ”€â”€ test_framework.py   # Framework tests
â”‚   â””â”€â”€ test_tools.py       # Tool tests
â”œâ”€â”€ config/                 # Configuration files
â”‚   â”œâ”€â”€ config.yaml         # Main configuration
â”‚   â””â”€â”€ config_enhanced.yaml # Enhanced agent configuration
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ NEW_TOOLS.md        # New tools documentation
â”‚   â”œâ”€â”€ REVIEW.md           # Code review notes
â”‚   â”œâ”€â”€ TESTING_GUIDE.md    # Testing guide
â”‚   â””â”€â”€ vllm/               # vLLM documentation
â”‚       â”œâ”€â”€ GPU_SUPPORT_GUIDE.md
â”‚       â”œâ”€â”€ ROCM_FIX_GUIDE.md
â”‚       â””â”€â”€ VLLM_INTEGRATION.md
â”œâ”€â”€ backends/               # Backend integrations
â”‚   â””â”€â”€ vllm/               # vLLM backend files
â”‚       â”œâ”€â”€ test_gpu_detection.sh
â”‚       â”œâ”€â”€ test_vllm_rocm.sh
â”‚       â”œâ”€â”€ vllm.conf.example
â”‚       â”œâ”€â”€ vllm_monitor.sh
â”‚       â”œâ”€â”€ vllm_rocm.conf.example
â”‚       â”œâ”€â”€ vllm_rocm_rx7900.conf
â”‚       â”œâ”€â”€ vllm_start_enhanced.sh
â”‚       â”œâ”€â”€ vllm_start_rocm.sh
â”‚       â””â”€â”€ vllm_start_universal.sh
â””â”€â”€ agent_memory/           # Persistent memory storage
    â””â”€â”€ memories/           # Memory files
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Add new tools or improve existing functionality
4. Test with both single and multi-agent modes
5. Submit a pull request

## ğŸ“ License

MIT License with Commercial Attribution Requirement

**For products with 100K+ users**: Please include attribution to Pietro Schirano and mention the "Make It Heavy" framework in your documentation or credits.

See [LICENSE](LICENSE) file for full details.

## ğŸ™ Acknowledgments

- Built with [OpenRouter](https://openrouter.ai/) for LLM API access
- Uses [uv](https://github.com/astral-sh/uv) for Python package management
- Inspired by **Grok heavy** mode and advanced multi-agent AI systems

---

**Ready to Chat with Tools?** ğŸš€

```bash
uv run council_chat.py
```

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Suparious/chat-with-tools&type=Date)](https://www.star-history.com/#Suparious/chat-with-tools&Date)
